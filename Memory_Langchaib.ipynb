{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tempfile\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "# --- Load envs (expects OPENAI_API_KEY and optional MLFLOW_TRACKING_URI) ---\n",
    "_ = load_dotenv(find_dotenv())\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "assert OPENAI_API_KEY, \"OPENAI_API_KEY missing in environment/.env\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Buffer Memory\n",
    "ConversationBufferMemory keeps a list of chat messages in a buffer and passes those into the prompt template.\n",
    "\n",
    "![Buffer Memory](https://miro.medium.com/v2/resize:fit:1400/format:webp/0*sUkvbURF633MXJyX.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/g4/9z6rn3xs13x2b0bkcf9ljwbw0000gp/T/ipykernel_7134/1027041917.py:12: LangChainDeprecationWarning: The class `ConversationChain` was deprecated in LangChain 0.2.7 and will be removed in 1.0. Use RunnableWithMessageHistory: https://api.python.langchain.com/en/latest/runnables/langchain_core.runnables.history.RunnableWithMessageHistory.html instead.\n",
      "  conversation = ConversationChain(\n",
      "/var/folders/g4/9z6rn3xs13x2b0bkcf9ljwbw0000gp/T/ipykernel_7134/1027041917.py:18: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 0.3.0. Use invoke instead.\n",
      "  print(conversation.run(\"Hi, my name is Tamil.\"))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: Hi, my name is Tamil.\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Hello, Tamil! It's great to meet you! How are you doing today?\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Hi, my name is Tamil.\n",
      "AI: Hello, Tamil! It's great to meet you! How are you doing today?\n",
      "Human: What is my name?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Your name is Tamil! It's nice to connect with you. How's your day going so far?\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.memory import ConversationBufferMemory #(Type -1 )\n",
    "from langchain.chains import ConversationChain\n",
    "\n",
    "# LLM\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "# Memory\n",
    "memory = ConversationBufferMemory()\n",
    "\n",
    "# Chain with memory\n",
    "conversation = ConversationChain(\n",
    "    llm=llm,\n",
    "    memory=memory,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "print(conversation.run(\"Hi, my name is Tamil.\"))\n",
    "print(conversation.run(\"What is my name?\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/g4/9z6rn3xs13x2b0bkcf9ljwbw0000gp/T/ipykernel_7134/1463898629.py:24: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use RunnableSequence, e.g., `prompt | llm` instead.\n",
      "  conversation = LLMChain(\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import (\n",
    "    ChatPromptTemplate,\n",
    "    MessagesPlaceholder,\n",
    "    SystemMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    ")\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "\n",
    "prompt = ChatPromptTemplate(\n",
    "    messages=[\n",
    "        SystemMessagePromptTemplate.from_template(\n",
    "            \"You are a nice chatbot having a conversation with a human.\"\n",
    "        ),\n",
    "        # The `variable_name` here is what must align with memory\n",
    "        MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "        HumanMessagePromptTemplate.from_template(\"{question}\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
    "\n",
    "conversation = LLMChain(\n",
    "    llm=llm,\n",
    "    prompt=prompt,\n",
    "    verbose=True,\n",
    "    memory=memory\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/g4/9z6rn3xs13x2b0bkcf9ljwbw0000gp/T/ipykernel_7134/2838645039.py:1: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 0.3.0. Use invoke instead.\n",
      "  conversation({\"question\": \"hi\"})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: You are a nice chatbot having a conversation with a human.\n",
      "Human: hi\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'question': 'hi',\n",
       " 'chat_history': [HumanMessage(content='hi'),\n",
       "  AIMessage(content='Hello! How can I assist you today?')],\n",
       " 'text': 'Hello! How can I assist you today?'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation({\"question\": \"hi\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: You are a nice chatbot having a conversation with a human.\n",
      "Human: hi\n",
      "AI: Hello! How can I assist you today?\n",
      "Human: My name is Tamil and I have 5 cows.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'question': 'My name is Tamil and I have 5 cows.',\n",
       " 'chat_history': [HumanMessage(content='hi'),\n",
       "  AIMessage(content='Hello! How can I assist you today?'),\n",
       "  HumanMessage(content='My name is Tamil and I have 5 cows.'),\n",
       "  AIMessage(content='Hi Tamil! That’s great to hear! Cows can be wonderful animals. Do you have any specific questions or topics related to your cows that you’d like to discuss?')],\n",
       " 'text': 'Hi Tamil! That’s great to hear! Cows can be wonderful animals. Do you have any specific questions or topics related to your cows that you’d like to discuss?'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation({\"question\": \"My name is Tamil and I have 5 cows.\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: You are a nice chatbot having a conversation with a human.\n",
      "Human: hi\n",
      "AI: Hello! How can I assist you today?\n",
      "Human: My name is Tamil and I have 5 cows.\n",
      "AI: Hi Tamil! That’s great to hear! Cows can be wonderful animals. Do you have any specific questions or topics related to your cows that you’d like to discuss?\n",
      "Human: how many cows i have?\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'question': 'how many cows i have?',\n",
       " 'chat_history': [HumanMessage(content='hi'),\n",
       "  AIMessage(content='Hello! How can I assist you today?'),\n",
       "  HumanMessage(content='My name is Tamil and I have 5 cows.'),\n",
       "  AIMessage(content='Hi Tamil! That’s great to hear! Cows can be wonderful animals. Do you have any specific questions or topics related to your cows that you’d like to discuss?'),\n",
       "  HumanMessage(content='how many cows i have?'),\n",
       "  AIMessage(content=\"You mentioned that you have 5 cows. Is there anything specific you'd like to share or ask about them?\")],\n",
       " 'text': \"You mentioned that you have 5 cows. Is there anything specific you'd like to share or ask about them?\"}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation({\"question\": \"how many cows i have?\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: You are a nice chatbot having a conversation with a human.\n",
      "Human: hi\n",
      "AI: Hello! How can I assist you today?\n",
      "Human: My name is Tamil and I have 5 cows.\n",
      "AI: Hi Tamil! That’s great to hear! Cows can be wonderful animals. Do you have any specific questions or topics related to your cows that you’d like to discuss?\n",
      "Human: how many cows i have?\n",
      "AI: You mentioned that you have 5 cows. Is there anything specific you'd like to share or ask about them?\n",
      "Human: Do you remember my name?\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'question': 'Do you remember my name?',\n",
       " 'chat_history': [HumanMessage(content='hi'),\n",
       "  AIMessage(content='Hello! How can I assist you today?'),\n",
       "  HumanMessage(content='My name is Tamil and I have 5 cows.'),\n",
       "  AIMessage(content='Hi Tamil! That’s great to hear! Cows can be wonderful animals. Do you have any specific questions or topics related to your cows that you’d like to discuss?'),\n",
       "  HumanMessage(content='how many cows i have?'),\n",
       "  AIMessage(content=\"You mentioned that you have 5 cows. Is there anything specific you'd like to share or ask about them?\"),\n",
       "  HumanMessage(content='Do you remember my name?'),\n",
       "  AIMessage(content='Yes, your name is Tamil! How can I help you today, Tamil?')],\n",
       " 'text': 'Yes, your name is Tamil! How can I help you today, Tamil?'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation({\"question\": \"Do you remember my name?\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[HumanMessage(content='hi'), AIMessage(content='Hello! How can I assist you today?'), HumanMessage(content='My name is Tamil and I have 5 cows.'), AIMessage(content='Hi Tamil! That’s great to hear! Cows can be wonderful animals. Do you have any specific questions or topics related to your cows that you’d like to discuss?'), HumanMessage(content='how many cows i have?'), AIMessage(content=\"You mentioned that you have 5 cows. Is there anything specific you'd like to share or ask about them?\"), HumanMessage(content='Do you remember my name?'), AIMessage(content='Yes, your name is Tamil! How can I help you today, Tamil?')]\n"
     ]
    }
   ],
   "source": [
    "print(memory.buffer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conversation Buffer Window Memory\n",
    "\n",
    "Similar to the previous one, but you can limit the number of conversational exchanges stored in memory. For example, you can set it so it only remembers the last 3 questions and answers of the conversation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[User 1]: Hi, I'm building a pizza chatbot for our shop.\n",
      "[Bot  1]: That sounds great! How can I assist you with your pizza chatbot? Do you need help with features, conversation flow, or something else?\n",
      "\n",
      "[User 2]: I like spicy paneer toppings.\n",
      "[Bot  2]: Spicy paneer is a delicious choice! Would you like to include it as a topping option in your chatbot? If so, I can help you with how to present it or incorporate it into the conversation flow.\n",
      "\n",
      "[User 3]: What would be a fun brand name?\n",
      "[Bot  3]: Here are some fun brand name ideas for your pizza shop:\n",
      "\n",
      "1. **Paneer Paradise**\n",
      "2. **Spicy Slice**\n",
      "3. **Cheesy Chaat**\n",
      "4. **Paneer Pizzazz**\n",
      "5. **Zesty Za**\n",
      "6. **Pizza Fiesta**\n",
      "7. **Spice & Slice**\n",
      "8. **Paneer Pizzicato**\n",
      "9. **Fiery Crust**\n",
      "10. **Topping Tango**\n",
      "\n",
      "Feel free to mix and match or modify them to suit your style!\n",
      "\n",
      "[User 4]: Remind me what topping I like, and suggest 2 names.\n",
      "[Bot  4]: You like spicy paneer toppings! Here are two brand name suggestions based on that:\n",
      "\n",
      "1. **Spicy Paneer Pizzeria**\n",
      "2. **Paneer Heat Pizza Co.**\n",
      "\n",
      "Let me know if you need more options!\n",
      "\n",
      "[User 5]: Also, what did I say first about my project?\n",
      "[Bot  5]: You mentioned that you like spicy paneer toppings. If you need more information or assistance with your project, feel free to ask!\n",
      "\n",
      "--- Memory window contents (history) ---\n",
      "Human  : Hi, I'm building a pizza chatbot for our shop.\n",
      "AI     : That sounds great! How can I assist you with your pizza chatbot? Do you need help with features, conversation flow, or something else?\n",
      "Human  : I like spicy paneer toppings.\n",
      "AI     : Spicy paneer is a delicious choice! Would you like to include it as a topping option in your chatbot? If so, I can help you with how to present it or incorporate it into the conversation flow.\n",
      "Human  : What would be a fun brand name?\n",
      "AI     : Here are some fun brand name ideas for your pizza shop:\n",
      "\n",
      "1. **Paneer Paradise**\n",
      "2. **Spicy Slice**\n",
      "3. **Cheesy Chaat**\n",
      "4. **Paneer Pizzazz**\n",
      "5. **Zesty Za**\n",
      "6. **Pizza Fiesta**\n",
      "7. **Spice & Slice**\n",
      "8. **Paneer Pizzicato**\n",
      "9. **Fiery Crust**\n",
      "10. **Topping Tango**\n",
      "\n",
      "Feel free to mix and match or modify them to suit your style!\n",
      "Human  : Remind me what topping I like, and suggest 2 names.\n",
      "AI     : You like spicy paneer toppings! Here are two brand name suggestions based on that:\n",
      "\n",
      "1. **Spicy Paneer Pizzeria**\n",
      "2. **Paneer Heat Pizza Co.**\n",
      "\n",
      "Let me know if you need more options!\n",
      "Human  : Also, what did I say first about my project?\n",
      "AI     : You mentioned that you like spicy paneer toppings. If you need more information or assistance with your project, feel free to ask!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.memory import ConversationBufferWindowMemory\n",
    "from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "# 1) Set your key: export OPENAI_API_KEY=sk-... (Linux/macOS) or set in env variables on Windows\n",
    "#    Or uncomment next line and paste directly (not recommended)\n",
    "# os.environ[\"OPENAI_API_KEY\"] = \"sk-...\"\n",
    "\n",
    "def make_chain(k_window: int = 3):\n",
    "    \"\"\"\n",
    "    Build a chat chain that only remembers the last k exchanges.\n",
    "    \"\"\"\n",
    "    llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.2)\n",
    "\n",
    "    # Memory that only keeps the last k turns\n",
    "    memory = ConversationBufferWindowMemory(\n",
    "        k=k_window,\n",
    "        memory_key=\"history\",\n",
    "        return_messages=True,   # important for ChatPromptTemplate\n",
    "    )\n",
    "\n",
    "    # Prompt that includes the rolling \"history\" plus the new user message\n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", \"You are a concise assistant.\"),\n",
    "        MessagesPlaceholder(variable_name=\"history\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ])\n",
    "\n",
    "    chain = LLMChain(llm=llm, prompt=prompt, memory=memory, verbose=False)\n",
    "    return chain, memory\n",
    "\n",
    "def demo():\n",
    "    chain, memory = make_chain(k_window=3)\n",
    "\n",
    "    user_messages = [\n",
    "        \"Hi, I'm building a pizza chatbot for our shop.\",\n",
    "        \"I like spicy paneer toppings.\",\n",
    "        \"What would be a fun brand name?\",\n",
    "        \"Remind me what topping I like, and suggest 2 names.\",\n",
    "        \"Also, what did I say first about my project?\",\n",
    "    ]\n",
    "\n",
    "    for i, msg in enumerate(user_messages, start=1):\n",
    "        print(f\"\\n[User {i}]: {msg}\")\n",
    "        reply = chain.run(input=msg)  # memory is applied automatically\n",
    "        print(f\"[Bot  {i}]: {reply}\")\n",
    "\n",
    "    # Inspect what's currently in memory (only the last k exchanges remain)\n",
    "    print(\"\\n--- Memory window contents (history) ---\")\n",
    "    for m in memory.chat_memory.messages:\n",
    "        role = type(m).__name__.replace(\"Message\", \"\")\n",
    "        print(f\"{role:7s}: {getattr(m, 'content', '')}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    demo()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chat Message History\n",
    "Save list of chat messages and then fetch them all."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ChatMessageHistory\n",
    "\n",
    "history = ChatMessageHistory()\n",
    "\n",
    "history.add_user_message(\"hi!\")\n",
    "\n",
    "history.add_ai_message(\"whats up?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='hi!'), AIMessage(content='whats up?')]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.messages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
